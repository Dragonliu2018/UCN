# 第6章 层次结构存储系统

## 0x01 基础知识

## 0x02 应试题目

### 01. 讨论题

#### 题目

假设在IA-32/Linux平台上运行一个C语言源程序P对应的用户进程，P中有一条循环语句S如下：

for \(i=0; i&lt;N; i++\) sum+=a\[i\];

已知变量sum和数组a都是short型，链接后确定a的首地址为0x804d000。假设编译器将a的首地址分配在EDX中，数组的下标变量i分配在ECX中，sum分配在EAX中，赋值语句“sum+=a\[i\];”仅用一条指令I实现。已知IA-32/Linux平台采用两级页表分页虚拟存储管理方式，页大小为4KB。假定系统中没有其他用户进程，请回答下列问题。

1. 假定指令I的地址为0x8049c08，则指令I所在页的虚页号是什么？页目录索引、页表索引和页内偏移量分别是什么？指令I在第一次执行过程中，有没有可能发生缺页异常？为什么？如果发生缺页异常的话，则页故障线性地址是什么？该地址会保存在哪个控制寄存器中？
2. 当i=60时，取数操作过程中MMU得到的操作数的线性地址是多少？当N=3000时（N为数组a的元素个数），则a占用几个页面？每个页的虚页号是什么？数组元素a\[1600\]在哪个页中？

#### 解答

1. 指令 $$I$$ 线性地址： $$0x0 +0x8049c08=0x8049c08$$ CS对应的段描述符中的基地址与指令地址相加 页大小 $$4KB=2^{12}B$$ ，页内偏移量为低12位\(0xc08 = 3080\)，高20位为虚页号\(0x08049 = 32841‬\)；其中高10位是页目录索引\(0x20 = 32\)，低10位是页表索引\(0x49 = 73\) 不可能，指令在循环中，前面有指令执行，所以不可能缺页； 但a\[0\]首地址为0x804d000是页面起始处，所在页面可能未被访问过。 页故障线性地址：0x804d000；CR2\(页故障线性地址寄存器\)
2. 有效地址： $$0x804d000+2*60=0x804 D078‬$$ 线性地址： $$0x804 D078‬+0x0=0x804 D078‬$$  N = 3000时，3000 \* 2 = 6000B，页面数：6000B / 4KB = 1.46 = 2个 虚页号：0x0804d 和 0x0804e a\[1600\] = 1601 \* 2 = 3202B &lt; 4KB，第一个页中。

## 0x03 讨论区

### 01. 无时不在的并行技术

* **问：**计算机体系结构提高性能的另一个方法是开发并行性。请大家来说一说计算机中都采用了哪些并行技术，以及它们分别实现了哪些层面的性能提升。
* **答**：

  * 线程级并发：有了进程的抽象，可以设计出同时执行多个程序的系统，这也就导致了并发。 单处理器系统，通过使一台计算机在它正在执行的进程间快速切换的方式模拟并发执行。 多处理器系统，使用线程，可以在一个进程中执行多个控制流；多核处理器是将多个CPU（”核“）集成到一个集成电路芯片上，每个核都有自己的L1和L2的高速缓存，但是它们共享一个更高层次的高速缓存，以及到主存的接口。 超线程：一项允许一个CPU执行多个控制流的技术。
  * 指令级并行：在较低的抽象层次上，现代处理器可以同时执行多条指令的属性称为指令级并行。如流水线的使用等。
  * 单指令、多数据并行：在最低层次上，许多现代处理器拥有特殊的硬件，允许一条指令产生多个可以并行执行的操作，即SIMD并行。
  * CPU和I/O接口之间的数据传输使用了并行技术，地址多少位就有多少线，实现了输入输出速度层面上的性能提升
  * 磁盘读写时，会用到并行交叉存取的技术，类似于内存的交叉编址，例如有多台磁盘驱动器，系统将每一盘块中的数据分为若干个子盘块数据，再把每一个子盘块的数据分别存储到各个不同磁盘中的相同位置上，这样即可实现同时输入输出多个盘块中的数据，使读写速度成倍提高。
  * 任务处理的并行，计算机可以将程序分解成多个任务并行处理，实现了软件层面的性能提升
  * 使用分支预测与乱序执行，通过分析指令间的相关性来决定指令的执行顺序，使得尽可能的并行减少时间花销，是指令级的并行技术，提高了运行程序的速度；
  * 计算机中可以有多条存储器总线并行传输数据。支持两条总线同时进行传输的内存插条槽为双通道内存插槽，还有三通道、四通道内存插槽，其总线的传输带宽可以分别提高到单通道的两倍、三倍、四倍。
  * 在Core i7的地址转换机制中，令cache组索引（CI）和块内偏移量（CO）的位数之和即物理页内偏移量（PPO）等于虚页内偏移量（VPO\)，使得访存过程中TLB和cache的部分操作（即MMU向TLB请求一个页表项的同时cache可以根据CI查找对应的cache组并读取Tag）是并行的。实现了微体系结构层面的性能提升，提高了存储访问的效率。

* **问**：并行技术的优势
* **答**：实现了时间，空间，资源等层面的节约
  * 时间重叠。在并行性概念中引入时间因素，即多个处理过程在时间上相互错开，轮流重叠地使用同一套硬件设备的各个部分，以加快硬件周转时间而赢得速度。
  * 资源重复。在并行性概念中引入空间因素，以数量取胜的原则，通过重复设置硬件资源，大幅度提髙计算机系统的性能。随着硬件价格的降低，这种方式在单处理机中广泛使用，而多处理机本身就是实施“资源重复”原理的结果。因此资源重复可称为空间并行技术。
  * 资源共享。这是一种软件方法，它使多个任务按一定时间顺序轮流使用同一套硬件设备。例如多道程序、分时系统就是遵循“资源共享”原理而产生的，资源共享既降低了成本，又提高了计算机设备的利用率。

### 02. 无处不在的缓存技术

* **问**：计算机体系结构提高性能的一个方法是运用缓存技术。通过本章的学习，你发现计算机中哪些地方采用了缓存技术？并说说它们具体的作用。
* **答**：
  * Cache高速缓冲存储器 ，复制保存了一些频繁使用的数据，便于快速访问
  * DRAM里面的行缓存，增加读数的效率
  * 网络空间和磁盘之间也有缓存技术，如HTTP缓存，将一些经常用到且不经常变化的数据存储在本地，以加快通过网络访问数据的速度。
  * 光驱缓存：光存储驱动器都带有内部缓冲器或高速缓存存储器。这些缓冲器是实际的存储芯片，安装在驱动器的电路板上，它在发送数据给PC之前可能准备或存储更大的数据段。
  * 因为直接调用系统调用开销太大，因此IO文件通常会在堆中创建一个缓冲区来作为缓存；
  * 数据库缓存：web在向应用服务器读取数据并展示到浏览器的过程中会多次向数据库请求，随着数据量的增大与访问的集中就会给服务器带来负担，造成数据库响应恶化，网站显示延迟等重大影响。为了解决该问题，采取了在内存中缓存数据库查询结果，下次查询时，直接从内存缓存返回结果，以加快访问速度，缓解数据库压力。
  * 硬件缓存：（如CPU、硬盘等）硬件缓存的存在主要是为了为了协调系统和硬件之间的读取速度而设计的
  * 软件缓存：（如浏览器,各种软件）有很多软件在运行时都会进行缓存，这些缓存会以临时文件方式储存于电脑磁盘中，当软件再次启动时，软件会优先从缓存中读取数据，这样无疑加快了软件的运行速度和数据处理速度。
  * 在段寄存器装入新选择符时，将新描述符装入描述符cache，运用了缓存技术，使得逻辑地址到线性地址转换过程中不必访问主存段表，直接用描述符cache中的信息，提高访问速度。

### 03. TLB与Cache的异同

* **异**：
  * 作用不同：TLB是一个内存管理单元用于改进虚拟地址到物理地址转换速度的缓存； cache是为了解决处理器与慢速DRAM\(慢速DRAM即内存\)设备之间巨大的速度差异而出现的。
  * 不同的系统层次： TLB是位于内存中的**页表的cache**，如果没有TLB，则每次取数据都需要两次访问内存,即查页表获得物理地址和取数据；cache属于硬件系统,linux不能管理cache.但会提供flush整个cache的接口. cache分为一级cache,二级cache,三级cache等等.一级cache与cpu处于同一个指令周期。
  * 局部性：cache中的数据存在时间局部性和空间局部性；TLB中的数据仅有时间局部性。
  * 写入的单位大小不同：TLB是单个的地址变换条目写入；而cache是根据块的大小复制块大小的数据
  * 存储内容不同：cache存放数据；TLB存放物理地址。
  * TLB和Cache结构不同：    Cache结构包括有效位、Tag、数据    ；TLB结构包括TLB标记字段、虚拟页存放位置、装入位、修改位、使用位、访问权限位、禁止缓存位组成
  * 位置不同：TLB在主存中，cache在CPU和主存之间（或者集成在CPU中）
* **同**：　
  * TLB是一种广义的Cache；
  * 对上层来说，TLB与Cache均是透明的。
* **参考：**
  * [TLB和cache的关系](https://blog.csdn.net/u014609236/article/details/39472115?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522159136625019725219950257%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=159136625019725219950257&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_v2~rank_v25-1-39472115.first_rank_v2_rank_v25&utm_term=TLB%E4%B8%8ECache%E5%BC%82%E5%90%8C)
  * [TLB与Cache有什么区别？](https://zhidao.baidu.com/question/938371428776271572.html)

### 04. 关于地址划分

* **问**：这一章我们学习了好几种地址，以及不同的地址划分方式，你能对常见的地址划分做个小结吗？
* **答**：
  * Cache
    * 直接映射：主存地址 = 标记 + cache行号 + 块内地址（标记 + cache行号 = 主存块号）
    * 全相联映射：主存地址 = 标记\(主存块号\) + 块内地址
    * 组相联映射：主存地址 = 标记 + cache组号 + 块内地址（标记 + cache组号 = 主存块号）
  * 分页式虚拟存储器
    * 虚拟地址 = 虚拟页号 + 页内地址（VA = VPN + VPO）
    * 物理地址 = 物理页号 + 页内地址（PA = PPN + PPO）
    * TLB全相联：VA = tag + VPO
    * TLB组相联：VA = tag + index + VPO
    * 多级页表：线性地址 = DIR\(页目录索引\) + PAGE\(页表索引\) + OFFSET\(页内偏移量\)
  * 分段式虚拟存储器
    * 虚拟地址 = 段号 + 段内地址
    * 物理地址 = 段起始地址 + 段内偏移
  * 段页式虚拟存储器
    * 逻辑地址 = 段号 + 页号 + 页内地址\(页内偏移量\)，物理地址要查表

### 05. 32位操作系统是否能支持4g以上的物理内存？

* **问**：在qq空间和同学讨论的一个问题，能或不能支持只取决于地址位数么？会不会与本节所学习的MMU一类的机制有关系？
* **答**：
  * PAE允许操作系统在32位模式下使用大于4G的物理内存；
  *  不管是否使用PAE，对于单个进程而言，32位系统下可见的地址空间最大只有4G；
  *  PAE的优势是可以让不同的进程（在不同的地址空间里）累计使用大于4G的内存，因此而达到使用超过4G内存的目的。
  *  WindowsXP系列虽然支持PAE，但实际在使用中最大内存限制在了4G，是人为限制的，原因：如果在XP系统（包括Vista）使用超过4G内存，会影响驱动的DMA，容易导致程序崩溃或者蓝屏，所以为了保持兼容性，XP不允许使用超过4G内存，server版因为一开始就与普通版不兼容，所以不存在兼容性的问题。
  * Linux则在开启PAE的模式下能支持在32位系统中使用超过4G的内存。



